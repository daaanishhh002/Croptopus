{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd555dc-4873-48df-9923-9bd7c89a689d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca912c-2a92-436a-b7cc-fe2630acc268",
   "metadata": {},
   "source": [
    "## Reading CSV Files\n",
    "\n",
    "[Data Link](https://raw.githubusercontent.com/Mubeenali53/CROPTOPUS/refs/heads/main/data/irrigation.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be762f8f-f5dd-4e29-acbd-1fba504dc53d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1294\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1340\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1339\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1289\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1048\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1051\u001b[0m \n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:986\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1459\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1459\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:952\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    951\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m--> 952\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(\n\u001b[0;32m    953\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address)\n\u001b[0;32m    954\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:827\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    826\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m getaddrinfo(host, port, \u001b[38;5;241m0\u001b[39m, SOCK_STREAM):\n\u001b[0;32m    828\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githuinplace=sercontent.com/Mubeenali53/CROPTOPUS/refs/heads/main/data/irrigation.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m irrigation \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(link)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    719\u001b[0m     path_or_buf,\n\u001b[0;32m    720\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    721\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    722\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    723\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    724\u001b[0m )\n\u001b[0;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "link = \"https://raw.githuinplace=sercontent.com/Mubeenali53/CROPTOPUS/refs/heads/main/data/irrigation.csv\"\n",
    "irrigation = pd.read_csv(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d3576-fd77-45af-88f6-36f31c5353d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "link = \"https://raw.githubusercontent.com/Mubeenali53/CROPTOPUS/refs/heads/main/data/npk.csv\"\n",
    "npk = pd.read_csv(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73fe4b93-78b4-4f9b-bad2-4b211412b73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "link = \"https://raw.githubusercontent.com/Mubeenali53/CROPTOPUS/refs/heads/main/data/soil.csv\"\n",
    "soil = pd.read_csv(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03843ace-a89f-4575-9f11-8f9304ec0f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "link = \"https://raw.githubusercontent.com/Mubeenali53/CROPTOPUS/refs/heads/main/data/rainfall.csv\"\n",
    "rainfall = pd.read_csv(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "242022c6-92d5-4df3-8e1d-4db32aa86b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "link = \"https://raw.githubusercontent.com/Mubeenali53/CROPTOPUS/refs/heads/main/data/yield.csv\"\n",
    "crop_yield = pd.read_csv(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02017d9-c0f6-49ba-abc0-5fd09c28d2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "link = \"./data/temp.csv\"\n",
    "temp = pd.read_csv(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88940a6-338a-4c3b-bb09-75f61460464d",
   "metadata": {},
   "source": [
    "## Pre-Processing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d877c5-eb6f-49a7-b44f-089695068b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_dataset(dataset, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Filters the dataset based on a year range and standardizes column names.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (pd.DataFrame): Input dataset to process.\n",
    "        start_year (int): Start year for filtering.\n",
    "        end_year (int): End year for filtering.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed dataset with filtered rows and updated column names.\n",
    "    \"\"\"\n",
    "    # Ensure the dataset has a 'year' column\n",
    "    if 'Year' not in dataset.columns:\n",
    "        raise ValueError(\"The dataset must contain a 'Year' column.\")\n",
    "\n",
    "    # Filter rows where 'Year' is within the specified range\n",
    "    filtered_dataset = dataset[(dataset['Year'] >= start_year) & (dataset['Year'] <= end_year)]\n",
    "    \n",
    "    # Update column names: lowercase and replace spaces with underscores\n",
    "    filtered_dataset.columns = filtered_dataset.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fe3ae-ed1c-4ba7-a04f-f81ec23ed1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = [irrigation, npk, rainfall, crop_yield, temp]\n",
    "processed_datasets = [process_dataset(df, 1990, 2017) for df in datasets]\n",
    "\n",
    "for i, df in enumerate(processed_datasets):\n",
    "    print(f\"Processed DataFrame {i+1}:\\n{df}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50f8c9-1ba2-4f69-898c-61ac396d8707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c871e-4997-4504-b5fa-4d8d90cbfef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v, w, x, y, z = processed_datasets\n",
    "a1 = pd.merge(v,w,on=['dist_code', 'state_code', 'year'],how='inner')\n",
    "b1 = pd.merge(a1,x,on=['dist_code', 'state_code', 'year'],how='inner')\n",
    "c1 = pd.merge(b1.drop(columns=['state_name_x', 'dist_name_x']), y, on=['dist_code', 'state_code', 'year'],how='inner')\n",
    "d1 = pd.merge(c1, z, on=['dist_code', 'state_code', 'year'],how='inner')\n",
    "# d1 = pd.merge(c1.drop(columns=['state_name_x', 'dist_name_x']), z, on=['dist_code', 'state_code', 'year'],how='inner')\n",
    "df = d1.loc[:, ~d1.T.duplicated()].drop(columns=['dist_name_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a8626-dcb2-4cae-bdfb-61431a280b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fav_cols = [\n",
    "    # Identifiers\n",
    "    'dist_code',\n",
    "    'year',\n",
    "    'state_code',\n",
    "    'state_name_y',\n",
    "    'dist_name_y',\n",
    "    \n",
    "    # # Irrigated Area Columns (in 1000 ha)\n",
    "    # 'rice_irrigated_area_(1000_ha)',\n",
    "    # 'wheat_irrigated_area_(1000_ha)',\n",
    "    # 'kharif_sorghum_irrigated_area_(1000_ha)',\n",
    "    # 'rabi_sorghum_irrigated_area_(1000_ha)',\n",
    "    # 'sorghum_irrigated_area_(1000_ha)',\n",
    "    # 'pearl_millet_irrigated_area_(1000_ha)',\n",
    "    # 'maize_irrigated_area_(1000_ha)',\n",
    "    # 'finger_millet_irrigated_area_(1000_ha)',\n",
    "    # 'barley_irrigated_area_(1000_ha)',\n",
    "    # 'chickpea_irrigated_area_(1000_ha)',\n",
    "    # 'pigeonpea_irrigated_area_(1000_ha)',\n",
    "    # 'minor_pulses_irrigated_area_(1000_ha)',\n",
    "    # 'pulses_irrigated_area_(1000_ha)',\n",
    "    # 'groundnut_irrigated_area_(1000_ha)',\n",
    "    # 'sesamum_irrigated_area_(1000_ha)',\n",
    "    # 'linseed_irrigated_area_(1000_ha)',\n",
    "    # 'sugarcane_irrigated_area_(1000_ha)',\n",
    "    # 'cotton_irrigated_area_(1000_ha)',\n",
    "\n",
    "    \n",
    "    # Nutrient Consumption and Share\n",
    "    'nitrogen_share_in_npk_(percent)',\n",
    "    'phosphate_share_in_npk_(percent)',\n",
    "    'potash_share_in_npk_(percent)',\n",
    "    \n",
    "    # Rainfall (millimeters)\n",
    "    'january_rainfall_(millimeters)',\n",
    "    'february_rainfall_(millimeters)',\n",
    "    'march_rainfall_(millimeters)',\n",
    "    'april_rainfall_(millimeters)',\n",
    "    'may_rainfall_(millimeters)',\n",
    "    'june_rainfall_(millimeters)',\n",
    "    'july_rainfall_(millimeters)',\n",
    "    'august_rainfall_(millimeters)',\n",
    "    'september_rainfall_(millimeters)',\n",
    "    'october_rainfall_(millimeters)',\n",
    "    'november_rainfall_(millimeters)',\n",
    "    'december_rainfall_(millimeters)',\n",
    "    'annual_rainfall_(millimeters)',\n",
    "    \n",
    "    # Yield (kg per ha)\n",
    "    'rice_yield_(kg_per_ha)',\n",
    "    'wheat_yield_(kg_per_ha)',\n",
    "    'kharif_sorghum_yield_(kg_per_ha)',\n",
    "    'rabi_sorghum_yield_(kg_per_ha)',\n",
    "    'sorghum_yield_(kg_per_ha)',\n",
    "    'pearl_millet_yield_(kg_per_ha)',\n",
    "    'maize_yield_(kg_per_ha)',\n",
    "    'finger_millet_yield_(kg_per_ha)',\n",
    "    'barley_yield_(kg_per_ha)',\n",
    "    'chickpea_yield_(kg_per_ha)',\n",
    "    'pigeonpea_yield_(kg_per_ha)',\n",
    "    'minor_pulses_yield_(kg_per_ha)',\n",
    "    'groundnut_yield_(kg_per_ha)',\n",
    "    'sesamum_yield_(kg_per_ha)',\n",
    "    'rapeseed_and_mustard_yield_(kg_per_ha)',\n",
    "    'safflower_yield_(kg_per_ha)',\n",
    "    'castor_yield_(kg_per_ha)',\n",
    "    'linseed_yield_(kg_per_ha)',\n",
    "    'sunflower_yield_(kg_per_ha)',\n",
    "    'soyabean_yield_(kg_per_ha)',\n",
    "    'oilseeds_yield_(kg_per_ha)',\n",
    "    'sugarcane_yield_(kg_per_ha)',\n",
    "    'cotton_yield_(kg_per_ha)',\n",
    "    \n",
    "    # Minimum Temperature\n",
    "    'january_minimum_temperature_(centigrate)',\n",
    "     'february_minimum_temperature_(centigrate)',\n",
    "     'march_minimum_temperature_(centigrate)',\n",
    "     'april_minimum_temperature_(centigrate)',\n",
    "     'may_minimum_temperature_(centigrate)',\n",
    "     'june_minimum_temperature_(centigrate)',\n",
    "     'july_minimum_temperature_(centigrate)',\n",
    "     'august_minimum_temperature_(centigrate)',\n",
    "     'september_minimum_temperature_(centigrate)',\n",
    "     'october_minimum_temperature_(centigrate)',\n",
    "     'november_minimum_temperature_(centigrate)',\n",
    "     'december_minimum_temperature_(centigrate)',\n",
    "    \n",
    "    # Maximum Temperature\n",
    "                'january_maximum_temperature_(centigrate)',\n",
    " 'february_maximum_temperature_(centigrate)',\n",
    " 'march_maximum_temperature_(centigrate)',\n",
    " 'april_maximum_temperature_(centigrate)',\n",
    " 'may_maximum_temperature_(centigrate)',\n",
    " 'june_maximum_temperature_(centigrate)',\n",
    " 'july_maximum_temperature_(centigrate)',\n",
    " 'august_maximum_temperature_(centigrate)',\n",
    " 'september_maximum_temperature_(centigrate)',\n",
    " 'october_maximum_temperature_(centigrate)',\n",
    " 'november_maximum_temperature_(centigrate)',\n",
    " 'december_maximum_temperature_(centigrate)',    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188c5e5-ebf6-4d55-b445-74a69c68e378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in fav_cols:\n",
    "        df.drop(columns=col, inplace=True)\n",
    "\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f3c61-912d-45d0-95be-a7efe12a6ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seasonal Aggregates\n",
    "df['rainfall_kharif'] = df[['june_rainfall_(millimeters)', 'july_rainfall_(millimeters)', 'august_rainfall_(millimeters)', 'september_rainfall_(millimeters)', 'october_rainfall_(millimeters)']].sum(axis=1)\n",
    "df['rainfall_rabi'] = df[['november_rainfall_(millimeters)', 'december_rainfall_(millimeters)', 'january_rainfall_(millimeters)', 'february_rainfall_(millimeters)', 'march_rainfall_(millimeters)']].sum(axis=1)\n",
    "df['rainfall_summer'] = df[['april_rainfall_(millimeters)', 'may_rainfall_(millimeters)']].sum(axis=1)\n",
    "\n",
    "# Drop monthly rainfall if no longer needed\n",
    "df = df.drop(columns=[f'{month}_rainfall_(millimeters)' for month in ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5316b-0f58-47ad-a60b-f623154541d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Average and range temperature columns for each season\n",
    "df['temp_kharif_avg'] = df[['june_maximum_temperature_(centigrate)',\n",
    " 'july_maximum_temperature_(centigrate)',\n",
    " 'august_maximum_temperature_(centigrate)',\n",
    " 'september_maximum_temperature_(centigrate)',\n",
    " 'october_maximum_temperature_(centigrate)',]].mean(axis=1)\n",
    "\n",
    "df['temp_rabi_avg'] = df[['november_maximum_temperature_(centigrate)',\n",
    " 'december_maximum_temperature_(centigrate)',\n",
    " 'january_maximum_temperature_(centigrate)',\n",
    " 'february_maximum_temperature_(centigrate)',\n",
    " 'march_maximum_temperature_(centigrate)',]].mean(axis=1)\n",
    "\n",
    "df['temp_summer_avg'] = df[['april_maximum_temperature_(centigrate)',\n",
    " 'may_maximum_temperature_(centigrate)',]].mean(axis=1)\n",
    "\n",
    "# df['temp_kharif_range'] = df[['Temp_Max_Jun', 'Temp_Max_Jul', 'Temp_Max_Aug', 'Temp_Max_Sep', 'Temp_Max_Oct']].max(axis=1) - \\\n",
    "#                           df[['Temp_Min_Jun', 'Temp_Min_Jul', 'Temp_Min_Aug', 'Temp_Min_Sep', 'Temp_Min_Oct']].min(axis=1)\n",
    "\n",
    "# df['temp_rabi_range'] = df[['Temp_Max_Nov', 'Temp_Max_Dec', 'Temp_Max_Jan', 'Temp_Max_Feb', 'Temp_Max_Mar']].max(axis=1) - \\\n",
    "#                          df[['Temp_Min_Nov', 'Temp_Min_Dec', 'Temp_Min_Jan', 'Temp_Min_Feb', 'Temp_Min_Mar']].min(axis=1)\n",
    "\n",
    "# Drop monthly temperature columns if not needed\n",
    "df = df.drop(columns=[f'{month}_maximum_temperature_(centigrate)' for month in ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']] +\n",
    "                     [f'{month}_minimum_temperature_(centigrate)' for month in ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d66045-a7ba-4a18-bf81-9be32cb815f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify crop yield columns\n",
    "yield_columns = [col for col in df.columns if 'yield' in col.lower()]\n",
    "\n",
    "# Debugging: Ensure yield columns are identified\n",
    "if not yield_columns:\n",
    "    raise ValueError(\"No yield columns found. Please verify the dataset column names.\")\n",
    "print(\"Yield columns identified:\", yield_columns)\n",
    "\n",
    "# Restructure the dataset\n",
    "id_vars = ['dist_code', 'year', 'state_code', 'state_name_y', 'dist_name_y',\n",
    "       'nitrogen_share_in_npk_(percent)', 'phosphate_share_in_npk_(percent)',\n",
    "       'potash_share_in_npk_(percent)', 'annual_rainfall_(millimeters)',\n",
    "       'rainfall_kharif', 'rainfall_rabi', 'rainfall_summer',\n",
    "       'temp_kharif_avg', 'temp_rabi_avg', 'temp_summer_avg']  # Explicit metadata columns\n",
    "try:\n",
    "    df_long = pd.melt(\n",
    "        df,\n",
    "        id_vars=id_vars,  # Keep metadata columns\n",
    "        value_vars=yield_columns,  # Reshape yield columns\n",
    "        var_name=\"Crop\",\n",
    "        value_name=\"Yield\"\n",
    "    )\n",
    "    print(\"Reshaping successful. New DataFrame shape:\", df_long.shape)\n",
    "except Exception as e:\n",
    "    print(\"Error during pd.melt:\", e)\n",
    "    raise\n",
    "\n",
    "# Clean the crop names\n",
    "df_long['Crop'] = df_long['Crop'].str.removesuffix('_yield_(kg_per_ha)')\n",
    "\n",
    "# Drop rows where yield is NaN\n",
    "# df_long = df_long.dropna(subset=[\"Yield\"])\n",
    "\n",
    "# Add normalized yield to act as a proxy for suitability\n",
    "# df_long['Normalized_Yield'] = df_long.groupby('Crop')['Yield'].transform(\n",
    "#     lambda x: (x - x.min()) / (x.max() - x.min() + 1e-9)  # Normalize within crop\n",
    "# )\n",
    "\n",
    "print(\"Data normalization successful.\")\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216882e5-462c-4b3a-9b9a-2d8ce77d746d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_long['temp_avg'] = (df_long['temp_kharif_avg'] + df_long['temp_rabi_avg'] + df_long['temp_summer_avg']) / 3\n",
    "df_long.drop(columns=['temp_summer_avg', 'temp_rabi_avg', 'temp_kharif_avg'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d19bc8-d151-431a-8dfa-7f10f880cbaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_long.drop(columns=['rainfall_kharif','rainfall_rabi', 'rainfall_summer'], inplace=True)\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "f0d3082f-c82a-43c0-98d6-bf3979730c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import randint\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba5922-2556-456d-9b9b-303d20fe908b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Forest Hyperparameter tuning\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 175, 250, 300],\n",
    "    'max_depth': [3, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 3, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Randomized Search for RFC\n",
    "rf_search = RandomizedSearchCV(rf_clf, param_distributions=rf_param_grid, n_iter=10, cv=3, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# Storing results\n",
    "results['Model'].append('Random Forest')\n",
    "results['Best Score'].append(rf_search.best_score_)\n",
    "results['Best Params'].append(rf_search.best_params_)\n",
    "\n",
    "print(\"Best Parameters for Random Forest Classifier:\", rf_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99538597-007c-46ce-b109-cfbd6dd65a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6003749-0406-4cff-bfc5-1fbc8938b379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1ad67-43ae-4494-a646-b02369238150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aaaed6-e271-499e-a2da-5458c7c3eb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262cb327-90a3-46f9-a356-a18951199e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10373a77-1de2-4c99-af1d-596cc922e92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba37c0-8fcd-4db5-b81e-426d01bbdfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153726f-3493-42d0-b320-33c91f4a1cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "428b4f01-0a5a-4b37-a1dd-6d5b61cce39e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.012000037"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long['temp_kharif_avg'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "6a45d6a7-efd0-4ce7-8c9c-7fdc201c8ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_code</th>\n",
       "      <th>year</th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name_y</th>\n",
       "      <th>dist_name_y</th>\n",
       "      <th>nitrogen_share_in_npk_(percent)</th>\n",
       "      <th>phosphate_share_in_npk_(percent)</th>\n",
       "      <th>potash_share_in_npk_(percent)</th>\n",
       "      <th>annual_rainfall_(millimeters)</th>\n",
       "      <th>rainfall_kharif</th>\n",
       "      <th>rainfall_rabi</th>\n",
       "      <th>rainfall_summer</th>\n",
       "      <th>temp_kharif_avg</th>\n",
       "      <th>temp_rabi_avg</th>\n",
       "      <th>temp_summer_avg</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Yield</th>\n",
       "      <th>Crop_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>14</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Durg</td>\n",
       "      <td>60.3</td>\n",
       "      <td>29.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1309.7</td>\n",
       "      <td>1168.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>129.4</td>\n",
       "      <td>31.112</td>\n",
       "      <td>30.238</td>\n",
       "      <td>39.215000</td>\n",
       "      <td>wheat</td>\n",
       "      <td>685.08</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>14</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Durg</td>\n",
       "      <td>48.1</td>\n",
       "      <td>38.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>764.9</td>\n",
       "      <td>741.5</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.796</td>\n",
       "      <td>30.158</td>\n",
       "      <td>40.299999</td>\n",
       "      <td>wheat</td>\n",
       "      <td>620.69</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>14</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Durg</td>\n",
       "      <td>54.3</td>\n",
       "      <td>32.9</td>\n",
       "      <td>12.8</td>\n",
       "      <td>923.2</td>\n",
       "      <td>826.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.140</td>\n",
       "      <td>29.912</td>\n",
       "      <td>40.575001</td>\n",
       "      <td>wheat</td>\n",
       "      <td>365.42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1993</td>\n",
       "      <td>14</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Durg</td>\n",
       "      <td>58.4</td>\n",
       "      <td>33.7</td>\n",
       "      <td>7.9</td>\n",
       "      <td>887.7</td>\n",
       "      <td>876.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.224</td>\n",
       "      <td>29.828</td>\n",
       "      <td>40.465000</td>\n",
       "      <td>wheat</td>\n",
       "      <td>704.14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1994</td>\n",
       "      <td>14</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Durg</td>\n",
       "      <td>62.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1462.9</td>\n",
       "      <td>1458.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.282</td>\n",
       "      <td>30.230</td>\n",
       "      <td>40.309999</td>\n",
       "      <td>wheat</td>\n",
       "      <td>805.48</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126103</th>\n",
       "      <td>916</td>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>Ranchi</td>\n",
       "      <td>63.9</td>\n",
       "      <td>27.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1583.9</td>\n",
       "      <td>1521.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>54.5</td>\n",
       "      <td>30.352</td>\n",
       "      <td>27.464</td>\n",
       "      <td>36.830000</td>\n",
       "      <td>cotton</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126104</th>\n",
       "      <td>916</td>\n",
       "      <td>2012</td>\n",
       "      <td>15</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>Ranchi</td>\n",
       "      <td>70.8</td>\n",
       "      <td>26.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1241.6</td>\n",
       "      <td>1031.9</td>\n",
       "      <td>181.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>30.928</td>\n",
       "      <td>26.850</td>\n",
       "      <td>37.844999</td>\n",
       "      <td>cotton</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126105</th>\n",
       "      <td>916</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>Ranchi</td>\n",
       "      <td>78.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1102.8</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>51.7</td>\n",
       "      <td>30.408</td>\n",
       "      <td>26.542</td>\n",
       "      <td>37.160002</td>\n",
       "      <td>cotton</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126106</th>\n",
       "      <td>916</td>\n",
       "      <td>2014</td>\n",
       "      <td>15</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>Ranchi</td>\n",
       "      <td>65.1</td>\n",
       "      <td>29.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>901.0</td>\n",
       "      <td>742.3</td>\n",
       "      <td>96.8</td>\n",
       "      <td>61.9</td>\n",
       "      <td>30.862</td>\n",
       "      <td>25.526</td>\n",
       "      <td>38.370001</td>\n",
       "      <td>cotton</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126107</th>\n",
       "      <td>916</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>Ranchi</td>\n",
       "      <td>68.3</td>\n",
       "      <td>27.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>873.4</td>\n",
       "      <td>773.6</td>\n",
       "      <td>24.3</td>\n",
       "      <td>75.5</td>\n",
       "      <td>31.042</td>\n",
       "      <td>26.034</td>\n",
       "      <td>36.844999</td>\n",
       "      <td>cotton</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126108 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dist_code  year  state_code  state_name_y dist_name_y  \\\n",
       "0               1  1990          14  Chhattisgarh        Durg   \n",
       "1               1  1991          14  Chhattisgarh        Durg   \n",
       "2               1  1992          14  Chhattisgarh        Durg   \n",
       "3               1  1993          14  Chhattisgarh        Durg   \n",
       "4               1  1994          14  Chhattisgarh        Durg   \n",
       "...           ...   ...         ...           ...         ...   \n",
       "126103        916  2011          15     Jharkhand      Ranchi   \n",
       "126104        916  2012          15     Jharkhand      Ranchi   \n",
       "126105        916  2013          15     Jharkhand      Ranchi   \n",
       "126106        916  2014          15     Jharkhand      Ranchi   \n",
       "126107        916  2015          15     Jharkhand      Ranchi   \n",
       "\n",
       "        nitrogen_share_in_npk_(percent)  phosphate_share_in_npk_(percent)  \\\n",
       "0                                  60.3                              29.9   \n",
       "1                                  48.1                              38.3   \n",
       "2                                  54.3                              32.9   \n",
       "3                                  58.4                              33.7   \n",
       "4                                  62.7                              29.6   \n",
       "...                                 ...                               ...   \n",
       "126103                             63.9                              27.7   \n",
       "126104                             70.8                              26.5   \n",
       "126105                             78.1                              18.0   \n",
       "126106                             65.1                              29.7   \n",
       "126107                             68.3                              27.8   \n",
       "\n",
       "        potash_share_in_npk_(percent)  annual_rainfall_(millimeters)  \\\n",
       "0                                 9.8                         1309.7   \n",
       "1                                13.7                          764.9   \n",
       "2                                12.8                          923.2   \n",
       "3                                 7.9                          887.7   \n",
       "4                                 7.8                         1462.9   \n",
       "...                               ...                            ...   \n",
       "126103                            8.4                         1583.9   \n",
       "126104                            2.8                         1241.6   \n",
       "126105                            3.9                         1102.8   \n",
       "126106                            5.2                          901.0   \n",
       "126107                            3.9                          873.4   \n",
       "\n",
       "        rainfall_kharif  rainfall_rabi  rainfall_summer  temp_kharif_avg  \\\n",
       "0                1168.7           11.6            129.4           31.112   \n",
       "1                 741.5           23.4              0.0           31.796   \n",
       "2                 826.8            4.0              0.0           32.140   \n",
       "3                 876.2           10.0              0.0           32.224   \n",
       "4                1458.9            1.0              3.0           31.282   \n",
       "...                 ...            ...              ...              ...   \n",
       "126103           1521.5            7.9             54.5           30.352   \n",
       "126104           1031.9          181.0             28.7           30.928   \n",
       "126105           1018.0           33.1             51.7           30.408   \n",
       "126106            742.3           96.8             61.9           30.862   \n",
       "126107            773.6           24.3             75.5           31.042   \n",
       "\n",
       "        temp_rabi_avg  temp_summer_avg    Crop   Yield  Crop_Encoded  \n",
       "0              30.238        39.215000   wheat  685.08            17  \n",
       "1              30.158        40.299999   wheat  620.69            17  \n",
       "2              29.912        40.575001   wheat  365.42            17  \n",
       "3              29.828        40.465000   wheat  704.14            17  \n",
       "4              30.230        40.309999   wheat  805.48            17  \n",
       "...               ...              ...     ...     ...           ...  \n",
       "126103         27.464        36.830000  cotton    0.00             2  \n",
       "126104         26.850        37.844999  cotton    0.00             2  \n",
       "126105         26.542        37.160002  cotton    0.00             2  \n",
       "126106         25.526        38.370001  cotton    0.00             2  \n",
       "126107         26.034        36.844999  cotton    0.00             2  \n",
       "\n",
       "[126108 rows x 18 columns]"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "5d4497ab-a4ea-4b6a-b073-157a049ce037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_longport necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load your dataset\n",
    "df = df_long\n",
    "\n",
    "# Features and target for classification\n",
    "features = ['dist_encoded', 'state_encoded' , 'nitrogen_share_in_npk_(percent)', 'phosphate_share_in_npk_(percent)',\n",
    "            'potash_share_in_npk_(percent)', 'annual_rainfall_(millimeters)',\n",
    "            'temp_avg']\n",
    "target = 'Crop'\n",
    "\n",
    "# Encode the target (Crop names)\n",
    "label_encoder = LabelEncoder()\n",
    "df['Crop_Encoded'] = label_encoder.fit_transform(df['Crop'])\n",
    "df['state_encoded'] = label_encoder.fit_transform(df['state_name_y'])\n",
    "df['dist_encoded'] = label_encoder.fit_transform(df['dist_name_y'])\n",
    "\n",
    "# Split data for classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df['Crop_Encoded'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "926213cf-c054-4b9e-8ed8-576b017990b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 18, does not match size of target_names, 285. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[834], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred, target_names\u001b[38;5;241m=\u001b[39mlabel_encoder\u001b[38;5;241m.\u001b[39mclasses_))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Predict top 5 crops for new input conditions\u001b[39;00m\n\u001b[0;32m     10\u001b[0m new_conditions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m9\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_avg\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m35\u001b[39m\n\u001b[0;32m     18\u001b[0m }])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2332\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2326\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2328\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2329\u001b[0m             )\n\u001b[0;32m   2330\u001b[0m         )\n\u001b[0;32m   2331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2336\u001b[0m         )\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2338\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 18, does not match size of target_names, 285. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Predict top 5 crops for new input conditions\n",
    "new_conditions = pd.DataFrame([{\n",
    "    'dist_encoded': 5,\n",
    "    'state_encoded': 9,\n",
    "    'nitrogen_share_in_npk_(percent)': 20,\n",
    "    'phosphate_share_in_npk_(percent)': 30,\n",
    "    'potash_share_in_npk_(percent)': 25,\n",
    "    'annual_rainfall_(millimeters)': 1200,\n",
    "    'temp_avg': 35\n",
    "}])\n",
    "\n",
    "# Get probabilities for all crops\n",
    "probabilities = clf.predict_proba(new_conditions)\n",
    "\n",
    "# Find top 5 crops with highest probabilities\n",
    "sorted_indices = probabilities.argsort(axis=1)[:, ::-1]  # Descending order\n",
    "top_5_indices = sorted_indices[0, :5]\n",
    "top_5_crops = [(label_encoder.inverse_transform([i])[0], probabilities[0, i]) for i in top_5_indices]\n",
    "\n",
    "print(\"Top 5 Crops with Success Probabilities:\")\n",
    "for crop, prob in top_5_crops:\n",
    "    print(f\"{crop}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "7156a225-6941-434c-8120-7fd8a6efdb94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Crops with Success Probabilities:\n",
      "soyabean: 76.28%\n",
      "minor_pulses: 64.09%\n",
      "safflower: 63.11%\n",
      "linseed: 62.91%\n",
      "rabi_sorghum: 62.47%\n"
     ]
    }
   ],
   "source": [
    "# Predict top 5 crops for new input conditions\n",
    "new_conditions = pd.DataFrame([{\n",
    "    'nitrogen_share_in_npk_(percent)': 60,\n",
    "    'phosphate_share_in_npk_(percent)': 55,\n",
    "    'potash_share_in_npk_(percent)': 20,\n",
    "    'annual_rainfall_(millimeters)': 250,\n",
    "    'rainfall_kharif': 150,\n",
    "    'rainfall_rabi': 100,\n",
    "    'rainfall_summer': 0,\n",
    "    'temp_kharif_avg': 28,\n",
    "    'temp_rabi_avg': 20,\n",
    "    'temp_summer_avg': 35\n",
    "}])\n",
    "\n",
    "# Get probabilities for all crops\n",
    "probabilities = clf.predict_proba(new_conditions)\n",
    "\n",
    "# Find top 5 crops with highest probabilities\n",
    "sorted_indices = probabilities.argsort(axis=1)[:, ::-1]  # Descending order\n",
    "top_5_indices = sorted_indices[0, :5]\n",
    "top_5_crops = [(label_encoder.inverse_transform([i])[0], probabilities[0, i]) for i in top_5_indices]\n",
    "\n",
    "print(\"Top 5 Crops with Success Probabilities:\")\n",
    "for crop, prob in top_5_crops:\n",
    "    print(f\"{crop}: {prob*10:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "1261c246-1d0f-467e-837f-2685b36a469e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "              barley       0.00      0.00      0.00    1428.0\n",
      "              castor       0.00      0.00      0.00    1372.0\n",
      "              cotton       0.00      0.00      0.00    1413.0\n",
      "       finger_millet       0.00      0.00      0.00    1400.0\n",
      "      kharif_sorghum       0.00      0.00      0.00    1392.0\n",
      "             linseed       0.00      0.00      0.00    1442.0\n",
      "               maize       0.00      0.00      0.00    1437.0\n",
      "        minor_pulses       0.00      0.00      0.00    1467.0\n",
      "            oilseeds       0.00      0.00      0.00    1325.0\n",
      "           pigeonpea       0.00      0.00      0.00    1365.0\n",
      "        rabi_sorghum       0.00      0.00      0.00    1417.0\n",
      "rapeseed_and_mustard       0.00      0.00      0.00    1445.0\n",
      "           safflower       0.00      0.00      0.00    1335.0\n",
      "             sesamum       0.00      0.00      0.00    1424.0\n",
      "             sorghum       0.00      0.00      0.00    1353.0\n",
      "            soyabean       0.00      0.00      0.00    1372.0\n",
      "           sunflower       0.00      0.00      0.00    1397.0\n",
      "               wheat       0.00      0.00      0.00    1438.0\n",
      "\n",
      "            accuracy                           0.00   25222.0\n",
      "           macro avg       0.00      0.00      0.00   25222.0\n",
      "        weighted avg       0.00      0.00      0.00   25222.0\n",
      "\n",
      "Feature Importance:\n",
      "nitrogen_share_in_npk_(percent): 11706.0\n",
      "phosphate_share_in_npk_(percent): 8630.0\n",
      "rainfall_rabi: 8512.0\n",
      "temp_kharif_avg: 8282.0\n",
      "rainfall_summer: 7994.0\n",
      "annual_rainfall_(millimeters): 7986.0\n",
      "temp_rabi_avg: 7870.0\n",
      "temp_summer_avg: 7593.0\n",
      "potash_share_in_npk_(percent): 7581.0\n",
      "rainfall_kharif: 6326.0\n",
      "\n",
      "Top 5 Crops with Success Probabilities (XGBoost):\n",
      "rabi_sorghum: 8.54%\n",
      "kharif_sorghum: 7.63%\n",
      "barley: 7.48%\n",
      "cotton: 7.22%\n",
      "sorghum: 7.08%\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convert data to DMatrix format (XGBoost-specific)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Train an XGBoost model\n",
    "xgb_params = {\n",
    "    'objective': 'multi:softprob',  # Multiclass classification\n",
    "    'num_class': len(label_encoder.classes_),  # Number of crops\n",
    "    'eval_metric': 'mlogloss',  # Multi-class log loss\n",
    "    'seed': 42\n",
    "}\n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = xgb_model.predict(dtest)\n",
    "y_pred = y_pred_probs.argmax(axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Feature importance\n",
    "xgb_importance = xgb_model.get_score(importance_type='weight')\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in sorted(xgb_importance.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "# Predict top 5 crops for new input conditions\n",
    "new_dmatrix = xgb.DMatrix(new_conditions)\n",
    "new_probs = xgb_model.predict(new_dmatrix)\n",
    "top_5_indices = new_probs.argsort(axis=1)[:, ::-1][0, :5]\n",
    "top_5_crops = [(label_encoder.inverse_transform([i])[0], new_probs[0, i]) for i in top_5_indices]\n",
    "\n",
    "print(\"\\nTop 5 Crops with Success Probabilities (XGBoost):\")\n",
    "for crop, prob in top_5_crops:\n",
    "    print(f\"{crop}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "4daacf47-b9a6-4905-8bc2-ffbcb1e634d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'verbose_eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[716], line 14\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train a LightGBM model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m lgb_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(label_encoder\u001b[38;5;241m.\u001b[39mclasses_),\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_logloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 14\u001b[0m lgb_model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(lgb_params, lgb_train, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, valid_sets\u001b[38;5;241m=\u001b[39m[lgb_train, lgb_test], verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Predict on test data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m y_pred_probs \u001b[38;5;241m=\u001b[39m lgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'verbose_eval'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Prepare data for LightGBM\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
    "\n",
    "# Train a LightGBM model\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(label_encoder.classes_),\n",
    "    'metric': 'multi_logloss',\n",
    "    'seed': 42\n",
    "}\n",
    "lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=100, valid_sets=[lgb_train, lgb_test], verbose_eval=10)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = lgb_model.predict(X_test)\n",
    "y_pred = y_pred_probs.argmax(axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Feature importance\n",
    "lgb_importance = lgb_model.feature_importance(importance_type='gain')\n",
    "print(\"\\nFeature Importance:\")\n",
    "for feature, importance in sorted(zip(features, lgb_importance), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "# Predict top 5 crops for new input conditions\n",
    "new_probs = lgb_model.predict(new_conditions)\n",
    "top_5_indices = new_probs.argsort(axis=1)[:, ::-1][0, :5]\n",
    "top_5_crops = [(label_encoder.inverse_transform([i])[0], new_probs[0, i]) for i in top_5_indices]\n",
    "\n",
    "print(\"\\nTop 5 Crops with Success Probabilities (LightGBM):\")\n",
    "for crop, prob in top_5_crops:\n",
    "    print(f\"{crop}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ed62a8-0c1c-4f1a-829a-978e9ed67182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_long' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train separate regression models for each crop\u001b[39;00m\n\u001b[0;32m      2\u001b[0m regression_models \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crop \u001b[38;5;129;01min\u001b[39;00m df_long[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrop\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Filter data for this crop\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     crop_data \u001b[38;5;241m=\u001b[39m df_long[df_long[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrop\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m crop]\n\u001b[0;32m      6\u001b[0m     X_crop \u001b[38;5;241m=\u001b[39m crop_data[features]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_long' is not defined"
     ]
    }
   ],
   "source": [
    "# Train separate regression models for each crop\n",
    "regression_models = {}\n",
    "for crop in df_long['Crop'].unique():\n",
    "    # Filter data for this crop\n",
    "    crop_data = df_long[df_long['Crop'] == crop]\n",
    "    X_crop = crop_data[features]\n",
    "    y_crop = crop_data['Yield']\n",
    "    \n",
    "    # Train a regression model\n",
    "    regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    regressor.fit(X_crop, y_crop)\n",
    "    regression_models[crop] = regressor\n",
    "\n",
    "# Predict yields for the top 5 crops\n",
    "print(\"\\nPredicted Yields for Top 5 Crops:\")\n",
    "for crop, prob in top_5_crops:\n",
    "    if crop in regression_models:\n",
    "        yield_pred = regression_models[crop].predict(new_conditions)[0]\n",
    "        print(f\"{crop}: {yield_pred:.2f} kg/ha (Success Probability: {prob:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388d64e-d43f-44a3-b588-0d98b8b331aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
